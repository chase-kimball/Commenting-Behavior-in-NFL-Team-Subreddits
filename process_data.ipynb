{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import glob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk import tokenize\n",
    "import nltk\n",
    "import datetime\n",
    "import pickle\n",
    "import pdb\n",
    "import os\n",
    "from utils import (process_coms,\n",
    "                 filter_processed_coms_by_date,\n",
    "                 get_sub_edges,\n",
    "                 get_division_edges,\n",
    "                 get_rivalry_graph,\n",
    "                 filter_comments_by_subs,\n",
    "                 get_division_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in list of subreddit names, initials, and flairs\n",
    "\n",
    "with open('nfl_subs.txt','r') as f:\n",
    "    subs = [s.strip() for s in f.readlines()]\n",
    "with open('nfl_flairs.txt','r') as f:\n",
    "    flairs = [fl.strip() for fl in f.readlines()]\n",
    "with open('nfl_inits.txt','r') as f:\n",
    "    inits = [i.strip() for i in f.readlines()]\n",
    "df = pd.DataFrame(dict(subreddit=subs, flair=flairs, inits=inits))\n",
    "teams=df\n",
    "team2abbrev = dict(zip(teams.subreddit,teams.inits))\n",
    "flair2team = dict(zip(teams.flair, teams.subreddit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial comment processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process raw comment data and analyze sentiment\n",
    "\n",
    "rerun = []\n",
    "nltk.download('punkt')\n",
    "for ii, filename in enumerate(glob.glob('data/nfl/comments/*.csv')):\n",
    "\n",
    "    subname = filename.split('/')[-1].split('.')[0]\n",
    "   \n",
    "    d, meta  = process_coms(filename, no_zero_sentiment=True)\n",
    "    if type(d) == str: \n",
    "        rerun.append(d)\n",
    "        continue\n",
    "\n",
    "             \n",
    "    if ii ==0:\n",
    "        metadata = meta\n",
    "    else:\n",
    "        for key in metadata:\n",
    "            metadata[key] += meta[key]\n",
    "    \n",
    "    d.to_csv('data/nfl_nonzero/processed/comments/{}.csv'.format(subname))    \n",
    "\n",
    "df = pd.DataFrame(metadata)\n",
    "df.to_csv('data/nfl_nonzero/processed/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organizing comments into NFL Weeks and season phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter processed coms by NFL Season Week and compute new metadata\n",
    "\n",
    "tag = '_nonzero' # Only include comments with non-zero sentiment scores\n",
    "dweek = datetime.timedelta(days= 7)\n",
    "\n",
    "\n",
    "for week in range(0,25):\n",
    "    \n",
    "    if week == 0:\n",
    "            \n",
    "        stopstring = '2022-09-08'\n",
    "        stop = datetime.datetime.fromisoformat(stopstring)\n",
    "        startstring = '2021-03-01'\n",
    "        start = datetime.datetime.fromisoformat(startstring)\n",
    "\n",
    "        print('week:{}'.format(week),start,stop)\n",
    "\n",
    "    elif week == 1:\n",
    "        startstring = '2022-09-08'\n",
    "        start = datetime.datetime.fromisoformat(startstring)\n",
    "        stop += dweek\n",
    "        print('week:{}'.format(week),start,stop)\n",
    "\n",
    "    else:\n",
    "        start += dweek\n",
    "        stop += dweek\n",
    "        print('week:{}'.format(week),start,stop)\n",
    "        \n",
    "    for ii, filename in enumerate(glob.glob('data/nfl'+tag+'/processed/comments/*.csv')):\n",
    "    \n",
    "        \n",
    "        subname = filename.split('/')[-1].split('.')[0]\n",
    "        d, meta  = filter_processed_coms_by_date(filename,start,stop)\n",
    "        \n",
    "        if type(d) == str: \n",
    "            print('help', d)\n",
    "            continue\n",
    "\n",
    "        if ii ==0:\n",
    "            metadata = meta\n",
    "        else:\n",
    "            for key in metadata:\n",
    "                metadata[key] += meta[key]\n",
    "        if not os.path.exists('data/nfl'+tag+'/weeks/{}'.format(str(week))):\n",
    "            os.mkdir('data/nfl'+tag+'/weeks/{}'.format(str(week)))\n",
    "            os.mkdir('data/nfl'+tag+'/weeks/{}/comments'.format(str(week)))\n",
    "\n",
    "        d.to_csv('data/nfl'+tag+'/weeks/{}/comments/{}.csv'.format(str(week),subname))\n",
    "    md = pd.DataFrame(metadata)\n",
    "    md.to_csv('data/nfl'+tag+'/weeks/{}/metadata.csv'.format(str(week)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "### Alternatively, collect all regular-season comments\n",
    "\n",
    "version = 'regular' #Need to do offseason 2022-03-01 2022-09-07\n",
    "which_nfl = 'nfl'\n",
    "for ii, filename in enumerate(glob.glob('data/{}/processed/comments/*.csv'.format(which_nfl))):\n",
    "    subname = filename.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    startstring = '2022-09-08'\n",
    "    start = datetime.datetime.fromisoformat(startstring)\n",
    "\n",
    "    stopstring = '2023-02-13'\n",
    "    stop = datetime.datetime.fromisoformat(stopstring)\n",
    "\n",
    "\n",
    "    d, meta  = filter_date(filename,start, stop)\n",
    "    if type(d) == str: \n",
    "        print(d)\n",
    "        continue\n",
    "    \n",
    "    for k, v in meta.items():\n",
    "        print(k,v)\n",
    "             \n",
    "    if ii ==0:\n",
    "        metadata = meta\n",
    "    else:\n",
    "        for key in metadata:\n",
    "            metadata[key] += meta[key]\n",
    "    d.to_csv('data/{}/{}/comments/{}.csv'.format(which_nfl, version, subname))\n",
    "df = pd.DataFrame(metadata)\n",
    "df.to_csv('data/{}/{}/metadata.csv'.format(which_nfl, version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "### Construct subreddit graph edges week by week ####\n",
    "\n",
    "for week in range(25):\n",
    "    all_edges = []\n",
    "\n",
    "    for ii, filename in enumerate(glob.glob('data/nfl_nonzero/weeks/{}/comments/*.csv'.format(week))):\n",
    "        edges = get_sub_edges(filename,teams.subreddit.values)\n",
    "        print(len(edges))\n",
    "\n",
    "\n",
    "\n",
    "        if type(edges) == str: \n",
    "            print(edges)\n",
    "            continue\n",
    "        all_edges.extend(edges)\n",
    "\n",
    "\n",
    "\n",
    "    with open('data/nfl_nonzero/weeks/{}/all_edges.pkl'.format(week),'wb') as f:\n",
    "        pickle.dump(all_edges, f)\n",
    "    \n",
    "    meta\n",
    "    \n",
    "### Construct subreddit graph edges in offseason, regular season, etc\n",
    "\n",
    "all_edges = []\n",
    "version = 'regular'\n",
    "for ii, filename in enumerate(glob.glob('data/nfl_nonzero/{}/comments/*.csv'.format(version))):\n",
    "    edges, meta = get_sub_edges(filename,teams.subreddit.values)\n",
    "    \n",
    "    \n",
    "   \n",
    "    if type(edges) == str: \n",
    "        print(edges)\n",
    "        continue\n",
    "    all_edges.extend(edges)\n",
    "    \n",
    "    for k, v in meta.items():\n",
    "        print(k,v)\n",
    "             \n",
    "    if ii ==0:\n",
    "        metadata = meta\n",
    "    else:\n",
    "        for key in metadata:\n",
    "            metadata[key] += meta[key]\n",
    "with open('data/nfl_nonzero/{}/all_edges.pkl'.format(version),'wb') as f:\n",
    "    pickle.dump(all_edges, f)\n",
    "dfm = pd.DataFrame(metadata)\n",
    "dfm.to_csv('data/nfl_nonzero/{}/edge_metadata.csv'.format(version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary info from graph edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for version in ['offseason','regular','playoffs']:\n",
    "    print(version)\n",
    "    edgefile = 'data/nfl_nonzero/{}/all_edges.pkl'.format(version)\n",
    "    data = dict(zip(teams.subreddit.values, [dict(in_weight = 0, out_weight=0, in_sent=0, out_sent=0, in_cont=0, out_cont=0, in_score = 0, out_score = 0) for team in teams.subreddit.values]))\n",
    "    with open(edgefile,'rb') as f:\n",
    "        all_edges = pickle.load(f)\n",
    "\n",
    "    \n",
    "    \n",
    "    for e in all_edges:\n",
    "        steam, tteam, weight, sent, cont, score = e\n",
    "        print('sent', sent)\n",
    "        if e[0] == e[1]: \n",
    "            data[steam]['self_sent'] = sent\n",
    "            continue\n",
    "        data[tteam]['in_weight'] += weight\n",
    "        data[tteam]['in_sent']+= sent\n",
    "        data[tteam]['in_cont'] += cont\n",
    "        data[tteam]['in_score'] += score\n",
    "\n",
    "        \n",
    "        data[steam]['out_weight'] += weight\n",
    "        data[steam]['out_sent']+= sent\n",
    "        data[steam]['out_cont'] += cont\n",
    "        data[steam]['out_score'] += score\n",
    "\n",
    "    for key,val in data.items():\n",
    "        for kk, vv in val.items():\n",
    "            if kk == 'self_sent': continue\n",
    "            data[key][kk]/=32.\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.transpose()\n",
    "    df['team'] = df.index.values\n",
    "    df.to_csv('data/summary_stats_in_{}.csv'.format(version), index=False)\n",
    "    \n",
    "    \n",
    "    with open('data/summary_dict_in_{}.pkl'.format(version),'wb') as f:\n",
    "        pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
